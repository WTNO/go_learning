queue给downloader提供了调度功能和限流的功能。 通过调用Schedule/ScheduleSkeleton来申请对任务进行调度，然后调用ReserveXXX方法来领取调度完成的任务，并在downloader里面的线程来执行，调用DeliverXXX方法把下载完的数据给queue。 最后通过WaitResults来获取已经完成的任务。中间还有一些对任务的额外控制，ExpireXXX用来控制任务是否超时， CancelXXX用来取消任务。

## Schedule方法
Schedule调用申请对一些区块头进行下载调度。可以看到做了一些合法性检查之后，把任务插入了blockTaskPool，blockTaskQueue，receiptTaskPool，receiptTaskQueue。 TaskPool是Map，用来记录header的hash是否存在。 TaskQueue是优先级队列，优先级是区块的高度的负数， 这样区块高度越小的优先级越高，就实现了首先调度小的任务的功能。
```go
// Schedule adds a set of headers for the download queue for scheduling, returning
// the new headers encountered.
// from表示headers里面第一个元素的区块高度。 返回值返回了所有被接收的header
func (q *queue) Schedule(headers []*types.Header, hashes []common.Hash, from uint64) []*types.Header {
	q.lock.Lock()
	defer q.lock.Unlock()

	// Insert all the headers prioritised by the contained block number
	inserts := make([]*types.Header, 0, len(headers))
	for i, header := range headers {
		// Make sure chain order is honoured and preserved throughout
		hash := hashes[i]
		// header.Number:此区块高度。用于对区块标注序号，在一条区块链上，区块高度必须是连续递增
		if header.Number == nil || header.Number.Uint64() != from {
			log.Warn("Header broke chain ordering", "number", header.Number, "hash", hash, "expected", from)
			break
		}
		// headerHead存储了最后一个插入的区块头， 检查当前区块是否正确的链接。
		if q.headerHead != (common.Hash{}) && q.headerHead != header.ParentHash {
			log.Warn("Header broke chain ancestry", "number", header.Number, "hash", hash)
			break
		}
		// 确保不执行重复的请求，即使区块为空也不能跳过，因为这会触发fetchResult的创建。
		// 检查重复，这里直接continue了，那不是from对不上了。
		if _, ok := q.blockTaskPool[hash]; ok {
			log.Warn("Header already scheduled for block fetch", "number", header.Number, "hash", hash)
		} else {
			q.blockTaskPool[hash] = header
			q.blockTaskQueue.Push(header, -int64(header.Number.Uint64()))
		}
		// Queue for receipt retrieval
		if q.mode == SnapSync && !header.EmptyReceipts() {
			if _, ok := q.receiptTaskPool[hash]; ok {
				log.Warn("Header already scheduled for receipt fetch", "number", header.Number, "hash", hash)
			} else {
				q.receiptTaskPool[hash] = header
				q.receiptTaskQueue.Push(header, -int64(header.Number.Uint64()))
			}
		}
		inserts = append(inserts, header)
		q.headerHead = hash
		from++
	}
	return inserts
}
```
> blockTaskQueue、receiptTaskQueue是Prque类型，通过堆实现了入堆排序功能，这里是以区块的高度的负数为优先级来排序， 这样区块高度越小的优先级越高，就实现了首先调度小的任务的功能。

## ReserveXXX
ReserveXXX方法用来从queue里面领取一些任务来执行。downloader里面的goroutine会调用这个方法来领取一些任务来执行。 这个方法直接调用了reserveHeaders方法。 所有的ReserveXXX方法都会调用reserveHeaders方法，除了传入的参数有一些区别。
```go
// 为给定的节点保留一组区块内容的获取请求，跳过任何先前失败的下载。
// 除了下一批需要获取的内容之外，它还返回一个标志，指示是否排队了空的区块需要进行处理。
func (q *queue) ReserveBodies(p *peerConnection, count int) (*fetchRequest, bool, bool) {
	q.lock.Lock()
	defer q.lock.Unlock()

	return q.reserveHeaders(p, count, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool, bodyType)
}
```

reserveHeaders
```go
// 为给定的节点保留一组数据下载操作，跳过任何先前失败的操作。
// 该方法是一个通用版本，被单独的特殊保留函数使用。
// 
// 注意，该方法期望队列锁已经被持有以进行写操作。
// 
//，所以它们已经需要一个锁。
//
// Returns:
//
//	item     - the fetchRequest
//	progress - whether any progress was made
//	throttle - if the caller should throttle for a while
// 这个方法调用的时候，假设已经获取到锁，这个方法里面没有锁的原因是参数已经传入到函数里面了，所以调用的时候就需要获取锁。
func (q *queue) reserveHeaders(p *peerConnection, count int, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque[int64, *types.Header],
	pendPool map[string]*fetchRequest, kind uint) (*fetchRequest, bool, bool) {
	// 如果连接池已经耗尽，或者节点已经在下载其他内容（为了确保状态不被破坏），则进行短路处理。
	if taskQueue.Empty() {
		return nil, false, true
	}
	// 如果这个peer还有下载任务没有完成
	if _, ok := pendPool[p.id]; ok {
		return nil, false, false
	}
	// 获取一批任务，跳过先前失败的任务。
	send := make([]*types.Header, 0, count)
	skip := make([]*types.Header, 0)
	progress := false
	throttled := false
	for proc := 0; len(send) < count && !taskQueue.Empty(); proc++ {
		// 任务队列将按顺序弹出项目，因此最高优先级的区块也是最低的区块编号。
		header, _ := taskQueue.Peek()

		// 我们可以向结果缓存询问该标题是否在“优先级”区块段内。如果不在，则需要进行限制。
        // AddFetch用于添加一个用于获取区块内容/收据的标题。当队列想要保留标题以进行获取时使用。
		stale, throttle, item, err := q.resultCache.AddFetch(header, q.mode == SnapSync)
		if stale {
			// 不要将此项放回任务队列，该项已经被传递给上游。
			taskQueue.PopItem()
			progress = true
			delete(taskPool, header.Hash())
			proc = proc - 1
			log.Error("Fetch reservation already delivered", "number", header.Number.Uint64())
			continue
		}
		if throttle {
			// 没有可用的结果槽。将其保留在任务队列中。
			// 但是，如果有任何被标记为“跳过”的结果槽，我们不应告诉调用者进行限制，
			// 因为我们仍希望其他节点为我们获取这些结果。
			throttled = len(skip) == 0
			break
		}
		if err != nil {
			// 这绝对不应该发生。
			log.Warn("Failed to reserve headers", "err", err)
			// 没有可用的结果槽。将其保留在任务队列中。
			break
		}
		if item.Done(kind) {
			// 如果这是一个空操作，则可以跳过此任务。
			delete(taskPool, header.Hash())
			taskQueue.PopItem()
			proc = proc - 1
			progress = true
			continue
		}
		// 将其从任务队列中移除。
		taskQueue.PopItem()
		// 否则，除非已知该节点没有这些数据，将其添加到检索列表中。
		// Lacks代表节点之前明确表示过没有这个hash的数据。
		if p.Lacks(header.Hash()) {
			skip = append(skip, header)
		} else {
			send = append(send, header)
		}
	}
	// 将所有跳过的headers合并回taskQueue
	for _, header := range skip {
		taskQueue.Push(header, -int64(header.Number.Uint64()))
	}
	// resultCache为已下载但尚未传递的获取结果。
	// 如果有可处理的项目可用，则HasCompletedItems返回true
	if q.resultCache.HasCompletedItems() {
		// Wake Results, resultCache was modified
		q.active.Signal()
	}
	// 组装并返回区块下载请求。
	if len(send) == 0 {
		return nil, progress, throttled
	}
	request := &fetchRequest{
		Peer:    p,
		Headers: send,
		Time:    time.Now(),
	}
	pendPool[p.id] = request
	return request, progress, throttled
}
```

ReserveReceipts 可以看到和ReserveBodys差不多。不过是队列换了而已。
```go
// 为给定的节点保留一组收据获取请求，跳过任何先前失败的下载。
// 除了下一批需要获取的收据之外，它还返回一个标志，指示是否排队了空的收据需要导入。
func (q *queue) ReserveReceipts(p *peerConnection, count int) (*fetchRequest, bool, bool) {
	q.lock.Lock()
	defer q.lock.Unlock()

	return q.reserveHeaders(p, count, q.receiptTaskPool, q.receiptTaskQueue, q.receiptPendPool, receiptType)
}

```

## DeliverXXX
Deliver方法在数据下载完之后会被调用。
```go
// DeliverBodies将区块内容获取的响应注入到results队列中。
// 该方法返回从传递中接受的区块内容的数量，并唤醒等待数据传递的线程。
func (q *queue) DeliverBodies(id string, txLists [][]*types.Transaction, txListHashes []common.Hash,
	uncleLists [][]*types.Header, uncleListHashes []common.Hash,
	withdrawalLists [][]*types.Withdrawal, withdrawalListHashes []common.Hash) (int, error) {
	q.lock.Lock()
	defer q.lock.Unlock()

	validate := func(index int, header *types.Header) error {
		if txListHashes[index] != header.TxHash {
			return errInvalidBody
		}
		if uncleListHashes[index] != header.UncleHash {
			return errInvalidBody
		}
		if header.WithdrawalsHash == nil {
			// nil hash means that withdrawals should not be present in body
			// 空的哈希意味着在区块内容中不应该有提款。
			if withdrawalLists[index] != nil {
				return errInvalidBody
			}
		} else { 
			// non-nil hash: body must have withdrawals
			// 非空的哈希：区块内容必须包含提款。
			if withdrawalLists[index] == nil {
				return errInvalidBody
			}
			if withdrawalListHashes[index] != *header.WithdrawalsHash {
				return errInvalidBody
			}
		}
		// 区块必须具有与标题燃气使用量相对应的一定数量的区块数据块，在Cancun硬分叉之前为零。
		var blobs int
		for _, tx := range txLists[index] {
			// 计算区块数据块的数量以与标题的dataGasUsed进行验证。dataGasUsed
			blobs += len(tx.BlobHashes())

			// Validate the data blobs individually too
			// 要逐个验证数据块。
			if tx.Type() == types.BlobTxType {
				if len(tx.BlobHashes()) == 0 {
					return errInvalidBody
				}
				for _, hash := range tx.BlobHashes() {
					if hash[0] != params.BlobTxHashVersion {
						return errInvalidBody
					}
				}
			}
		}
		if header.DataGasUsed != nil {
			if want := *header.DataGasUsed / params.BlobTxDataGasPerBlob; uint64(blobs) != want { // 除法是因为header肯定是正确的，而区块内容可能会过于臃肿。
				return errInvalidBody
			}
		} else {
			if blobs != 0 {
				return errInvalidBody
			}
		}
		return nil
	}

	reconstruct := func(index int, result *fetchResult) {
		result.Transactions = txLists[index]
		result.Uncles = uncleLists[index]
		result.Withdrawals = withdrawalLists[index]
		result.SetBodyDone()
	}
	return q.deliver(id, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool,
		bodyReqTimer, bodyInMeter, bodyDropMeter, len(txLists), validate, reconstruct)
}
```

deliver方法
```go
// deliver方法将数据检索响应注入到结果队列中。
//
// 请注意，该方法期望队列锁已经被写入持有。
// 之所以在这里不获取锁是因为参数已经需要访问队列，所以它们已经需要锁定。
func (q *queue) deliver(id string, taskPool map[common.Hash]*types.Header,
	taskQueue *prque.Prque[int64, *types.Header], pendPool map[string]*fetchRequest,
	reqTimer metrics.Timer, resInMeter metrics.Meter, resDropMeter metrics.Meter,
	results int, validate func(index int, header *types.Header) error,
	reconstruct func(index int, result *fetchResult)) (int, error) {
	// Short circuit if the data was never requested
	// 检查数据是否从来没有请求过。
	request := pendPool[id]
	if request == nil {
		resDropMeter.Mark(int64(results))
		return 0, errNoFetchesPending
	}
	delete(pendPool, id)

	reqTimer.UpdateSince(request.Time)
	resInMeter.Mark(int64(results))

	// 如果没有检索到数据项，则将其标记为对原始节点不可用。
	if results == 0 {
		// 如果结果为空。 那么标识这个peer没有这些数据。
		for _, header := range request.Headers {
			request.Peer.MarkLacking(header.Hash())
		}
	}
	// 将每个结果与其标头和已检索的数据部分组装在一起。
	var (
		accepted int
		failure  error
		i        int
		hashes   []common.Hash
	)
	for _, header := range request.Headers {
		// Short circuit assembly if no more fetch results are found
		if i >= results {
			break
		}
		// Validate the fields
		if err := validate(i, header); err != nil {
			failure = err
			break
		}
		hashes = append(hashes, header.Hash())
		i++
	}

	for _, header := range request.Headers[:i] {
		if res, stale, err := q.resultCache.GetDeliverySlot(header.Number.Uint64()); err == nil && !stale {
			reconstruct(accepted, res)
		} else {
			// else: 在此处和上述之间，其他节点填充了此结果，或者确实是一个无操作。这不应该发生，但如果发生了，也不是什么值得恐慌的事情。
			log.Error("Delivery stale", "stale", stale, "number", header.Number.Uint64(), "err", err)
			failure = errStaleDelivery
		}
		// Clean up a successful fetch
		delete(taskPool, hashes[accepted])
		accepted++
	}
	resDropMeter.Mark(int64(results - accepted))

	// Return all failed or missing fetches to the queue
	// 所有没有成功的请求加入taskQueue
	for _, header := range request.Headers[accepted:] {
		taskQueue.Push(header, -int64(header.Number.Uint64()))
	}
	// Wake up Results
	// 如果结果有变更，通知WaitResults线程启动。
	if accepted > 0 {
		q.active.Signal()
	}
	if failure == nil {
		return accepted, nil
	}
	// 如果没有任何数据是有效的，则是一个陈旧的传递。
	if accepted > 0 {
		return accepted, fmt.Errorf("partial failure: %v", failure)
	}
	return accepted, fmt.Errorf("%w: %v", failure, errStaleDelivery)
}
```

## ExpireXXX and CancelXXX
### ExpireXXX
ExpireBodies函数获取了锁，然后直接调用了expire函数。
```go
// 检查超过超时限制的正在进行中的块主体请求，取消它们并返回负责进行惩罚的节点。
func (q *queue) ExpireBodies(peer string) int {
	q.lock.Lock()
	defer q.lock.Unlock()

	bodyTimeoutMeter.Mark(1)
	return q.expire(peer, q.blockPendPool, q.blockTaskQueue)
}
```

expire函数
```go
// expire是一个通用的检查方法，将特定的过期任务从待处理池移回任务池。
// 传递给taskQueue的语法有些奇怪，因为我们需要一个通用的expire方法来处理两种类型，
// 但目前至少还不支持（Go 1.19）。
// 
// 请注意，该方法期望队列锁已经被持有。
// 之所以在此处不获取锁是因为参数已经需要访问队列，所以它们已经需要锁定。
func (q *queue) expire(peer string, pendPool map[string]*fetchRequest, taskQueue interface{}) int {
	// 获取被过期的请求并在其不存在时记录错误，因为没有任何事件顺序应该导致这种过期。
	req := pendPool[peer]
	if req == nil {
		log.Error("Expired request does not exist", "peer", peer)
		return 0
	}
	delete(pendPool, peer)

	// Return any non-satisfied requests to the pool
	if req.From > 0 {
		taskQueue.(*prque.Prque[int64, uint64]).Push(req.From, -int64(req.From))
	}
	for _, header := range req.Headers {
		taskQueue.(*prque.Prque[int64, *types.Header]).Push(header, -int64(header.Number.Uint64()))
	}
	return len(req.Headers)
}
```



























