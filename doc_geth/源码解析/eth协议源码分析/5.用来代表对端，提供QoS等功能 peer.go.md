peer模块包含了downloader使用的peer节点，封装了吞吐量，是否空闲，并记录了之前失败的信息。

### peer
```go
// eth/downloader/peer.go
// peerConnection表示一个活动的对等节点，从该节点检索哈希值和区块。
type peerConnection struct {
	id string // 节点的唯一标识符

	rates   *msgrate.Tracker         // Tracker用于定位每秒可检索的项目数量。
	lacking map[common.Hash]struct{} // 不要请求的哈希集合（之前没有的）。

	peer Peer

	version uint       // 以太坊协议版本号用于切换策略。
	log     log.Logger // 上下文日志记录器用于向对等节点日志添加额外信息。
	lock    sync.RWMutex
}

// les/downloader/peer.go
// peerConnection represents an active peer from which hashes and blocks are retrieved.
type peerConnection struct {
    id string // Unique identifier of the peer
    
    headerIdle  int32 // Current header activity state of the peer (idle = 0, active = 1)
    blockIdle   int32 // Current block activity state of the peer (idle = 0, active = 1)
    receiptIdle int32 // Current receipt activity state of the peer (idle = 0, active = 1)
    stateIdle   int32 // Current node data activity state of the peer (idle = 0, active = 1)
    
    headerStarted  time.Time // Time instance when the last header fetch was started
    blockStarted   time.Time // Time instance when the last block (body) fetch was started
    receiptStarted time.Time // Time instance when the last receipt fetch was started
    stateStarted   time.Time // Time instance when the last node data fetch was started
    
    rates   *msgrate.Tracker         // Tracker to hone in on the number of items retrievable per second
    lacking map[common.Hash]struct{} // Set of hashes not to request (didn't have previously)
    
    peer Peer
    
    version uint       // Eth protocol version number to switch strategies
    log     log.Logger // Contextual logger to add extra infos to peer logs
    lock    sync.RWMutex
}
```

#### FetchXXX
FetchHeaders、FetchBodies等函数 主要调用了eth.peer的功能来进行发送数据请求。
```go
// FetchHeaders sends a header retrieval request to the remote peer.
func (p *peerConnection) FetchHeaders(from uint64, count int) error {
	// Short circuit if the peer is already fetching
	if !atomic.CompareAndSwapInt32(&p.headerIdle, 0, 1) {
		return errAlreadyFetching
	}
	p.headerStarted = time.Now()

	// Issue the header retrieval request (absolute upwards without gaps)
	go p.peer.RequestHeadersByNumber(from, count, 0, false)

	return nil
}
```
> 本方法位于les/downloader/peer.go中，而不是eth/downloader/peer.go

#### SetXXXIdle
SetHeadersIdle, SetBlocksIdle 等函数 设置peer的状态为空闲状态，允许它执行新的请求。 同时还会通过本次传输的数据的多少来重新评估链路的吞吐量。
```go
// SetHeadersIdle将对等节点设置为空闲状态，允许其执行新的头部检索请求。它的估计头部检索吞吐量(estimated header retrieval throughput)将根据刚刚测量的值进行更新。
func (p *peerConnection) SetHeadersIdle(delivered int, deliveryTime time.Time) {
	p.rates.Update(eth.BlockHeadersMsg, deliveryTime.Sub(p.headerStarted), delivered)
	atomic.StoreInt32(&p.headerIdle, 0)
}
```

p2p/msgrate/msgrate.go/Update
```go
// Update使用新的测量值修改对等节点特定数据类型的容量值。
// 如果交付量为零，假定对等节点要么超时，要么没有请求的数据，导致容量值被减为零。
// 这样可以避免分配对等节点无法满足的检索任务。
func (t *Tracker) Update(kind uint64, elapsed time.Duration, items int) {
	t.lock.Lock()
	defer t.lock.Unlock()

	// If nothing was delivered (timeout / unavailable data), reduce throughput
	// to minimum
	if items == 0 {
		t.capacity[kind] = 0
		return
	}
	// Otherwise update the throughput with a new measurement
	if elapsed <= 0 {
		elapsed = 1 // +1 (ns) to ensure non-zero divisor
	}
	measured := float64(items) / (float64(elapsed) / float64(time.Second))

	// measurementImpact = 0.1 , 新的吞吐量=老的吞吐量*0.9 + 这次的吞吐量*0.1
	t.capacity[kind] = (1-measurementImpact)*(t.capacity[kind]) + measurementImpact*measured
	// 更新roundtrip time(对等节点通常响应数据请求的延迟)
	t.roundtrip = time.Duration((1-measurementImpact)*float64(t.roundtrip) + measurementImpact*float64(elapsed))
}
```
> 往返时间（roundtrip）是对等节点通常响应数据请求的延迟。这个数字在追踪器内部不被使用，但可以用于比较对等节点并筛选出响应慢的节点。然而，请注意，只有在调用者为每个对等节点的请求大小定制以达到相同的往返时间时，比较往返时间才有意义。我们并不需要将这个数字设置为真实的网络往返时间，我们只需要一个用于比较对等节点的数字。

#### XXXCapacity
用来返回当前的链接允许的吞吐量
```go
// HeaderCapacity 根据之前发现的吞吐量检索对等节点的头部下载配额。
func (p *peerConnection) HeaderCapacity(targetRTT time.Duration) int {
	cap := p.rates.Capacity(eth.BlockHeadersMsg, targetRTT)
	if cap > MaxHeaderFetch {
		cap = MaxHeaderFetch
	}
	return cap
}
```

#### Lacks 
用来标记上次是否失败，以便下次同样的请求不通过这个peer
```go
// 检索区块链项目的哈希是否在对等节点的缺失列表中（即我们知道对等节点没有该项目）。
func (p *peerConnection) Lacks(hash common.Hash) bool {
	p.lock.RLock()
	defer p.lock.RUnlock()

	_, ok := p.lacking[hash]
	return ok
}
```

### peerSet
```go
// peerSet表示参与链下载过程的活动对等节点的集合。
type peerSet struct {
	peers  map[string]*peerConnection
	rates  *msgrate.Trackers // Set of rate trackers to give the sync a common beat
	events event.Feed        // Feed to publish peer lifecycle events on

	lock sync.RWMutex
}
```

#### Register 和 UnRegister
```go
// Register将一个新的节点注入到工作集中，如果该节点已经存在，则返回错误。
// 
// 该方法还将新节点的起始吞吐量值设置为所有现有节点的平均值，以便为数据检索提供一个真实的机会。
func (ps *peerSet) Register(p *peerConnection) error {
	// 使用一些有意义的默认值注册新的节点。
	ps.lock.Lock()
	if _, ok := ps.peers[p.id]; ok {
		ps.lock.Unlock()
		return errAlreadyRegistered
	}
	p.rates = msgrate.NewTracker(ps.rates.MeanCapacities(), ps.rates.MedianRoundTrip())
	if err := ps.rates.Track(p.id, p.rates); err != nil {
		ps.lock.Unlock()
		return err
	}
	ps.peers[p.id] = p
	ps.lock.Unlock()

	ps.events.Send(&peeringEvent{peer: p, join: true})
	return nil
}

// Unregister从活动集中移除一个远程节点，禁用与该特定实体的任何进一步操作。
func (ps *peerSet) Unregister(id string) error {
	ps.lock.Lock()
	p, ok := ps.peers[id]
	if !ok {
		ps.lock.Unlock()
		return errNotRegistered
	}
	delete(ps.peers, id)
	ps.rates.Untrack(id)
	ps.lock.Unlock()

	ps.events.Send(&peeringEvent{peer: p, join: false})
	return nil
}
```

#### XXXIdlePeers
`eth/downloader/peer.go`中已经移除这系列方法，`les/downloader/peer.go`中保留着
```go
// HeaderIdlePeers检索活动节点集中当前所有处于头部空闲状态的节点的平面列表，
// 按照它们的reputation进行排序。
func (ps *peerSet) HeaderIdlePeers() ([]*peerConnection, int) {
	idle := func(p *peerConnection) bool {
		return atomic.LoadInt32(&p.headerIdle) == 0
	}
	throughput := func(p *peerConnection) int {
		return p.rates.Capacity(eth.BlockHeadersMsg, time.Second)
	}
	return ps.idlePeers(eth.ETH66, eth.ETH67, idle, throughput)
}

// idlePeers使用提供的函数检查空闲状态，检索满足协议版本约束条件的所有当前空闲节点的平面列表。
// 所得到的节点集按照它们的容量进行排序。
func (ps *peerSet) idlePeers(minProtocol, maxProtocol uint, idleCheck func(*peerConnection) bool, capacity func(*peerConnection) int) ([]*peerConnection, int) {
    ps.lock.RLock()
    defer ps.lock.RUnlock()
    
    var (
        total = 0
        idle  = make([]*peerConnection, 0, len(ps.peers))
        tps   = make([]int, 0, len(ps.peers))
    )
    for _, p := range ps.peers {
        if p.version >= minProtocol && p.version <= maxProtocol {
            if idleCheck(p) {
                idle = append(idle, p)
                tps = append(tps, capacity(p))
            }
            total++
        }
    }
    
    // And sort them
    sortPeers := &peerCapacitySort{idle, tps}
    sort.Sort(sortPeers)
    return sortPeers.p, total
}
```

#### ~~medianRTT~~ -> MedianRoundTrip
```go
// MedianRoundTrip返回所有已知跟踪器的中位数往返时间（RTT）。
// 中位数RTT的目的是使用合理的统计数据初始化新节点，希望它能表现得更好。
// 如果它表现严重不佳，有可能会丢弃该节点，但这没关系，因为我们的目标是一个强大的中位数。
func (t *Trackers) MedianRoundTrip() time.Duration {
    t.lock.RLock()
    defer t.lock.RUnlock()
    
    return t.medianRoundTrip()
}
// 用于QoS调节器的内部无锁版本的MedianRoundTrip函数
func (t *Trackers) medianRoundTrip() time.Duration {
	// Gather all the currently measured round trip times
	rtts := make([]float64, 0, len(t.trackers))
	for _, tt := range t.trackers {
		tt.lock.RLock()
		rtts = append(rtts, float64(tt.roundtrip))
		tt.lock.RUnlock()
	}
	sort.Float64s(rtts)

	var median time.Duration
	switch len(rtts) {
	case 0:
		median = rttMaxEstimate
	case 1:
		median = time.Duration(rtts[0])
	default:
		idx := int(math.Sqrt(float64(len(rtts))))
		median = time.Duration(rtts[idx])
	}
	// Restrict the RTT into some QoS defaults, irrelevant of true RTT
	if median < rttMinEstimate {
		median = rttMinEstimate
	}
	if median > rttMaxEstimate {
		median = rttMaxEstimate
	}
	return median
}
```































