## core/bloombits/scheduler.go
scheduler是基于section的布隆过滤器的单个bit值检索的调度。 除了调度检索操作之外，这个结构还可以对请求进行重复数据删除并缓存结果，从而即使在复杂的过滤情况下也可以将网络/数据库开销降至最低。

### 数据结构
request表示一个bloom检索任务，以便优先从本地数据库中或从网络中剪检索。 section 表示区块段号，每段4096个区块， bit代表检索的是布隆过滤器的哪一位(一共有2048位)。这个在之前的(eth-bloombits和filter源码分析.md)中有介绍。
```go
// 请求表示一个布隆过滤器检索任务，可以优先从本地数据库中获取，或者从网络中远程获取。
type request struct {
	section uint64 // 要从中检索位向量的部分索引
	bit     uint   // 要检索向量的位索引在部分内部。
}
```

response当前调度的请求的状态。 没发送一个请求，会生成一个response对象来最终这个请求的状态。 cached用来缓存这个section的结果。
```go
// 响应表示通过调度器请求的位向量的状态。
type response struct {
	cached []byte        // 使用缓存位来去重多个请求
	done   chan struct{} // 使用通道等待完成。
}
```

scheduler
```go
// 调度器负责对属于单个布隆位的整个部分批次进行布隆过滤器检索操作的调度。
// 除了调度检索操作外，该结构体还对请求进行去重，并缓存结果，
// 以在复杂的过滤场景中最小化网络/数据库开销。
type scheduler struct {
	bit       uint                 // 该调度器负责的布隆过滤器中的位的索引
	responses map[uint64]*response // 当前待处理的检索请求或已缓存的响应
	lock      sync.Mutex           // 用于保护响应免受并发访问的锁
}
```

### 构造函数
```go
// newScheduler为特定的位索引创建一个新的布隆过滤器检索调度器。
func newScheduler(idx uint) *scheduler {
	return &scheduler{
		bit:       idx,
		responses: make(map[uint64]*response),
	}
}
```

reset方法
```go
// reset清理之前运行中的任何残留物。在重新启动之前，
// 这是必需的，以确保之前请求但从未交付的状态不会导致死锁。
func (s *scheduler) reset() {
	s.lock.Lock()
	defer s.lock.Unlock()

	for section, res := range s.responses {
		if res.cached == nil {
			delete(s.responses, section)
		}
	}
}
```

### 运行run方法
run方法创建了一个流水线， 从sections channel来接收需要请求的sections，通过done channel来按照请求的顺序返回结果。 并发的运行同样的scheduler是可以的，这样会导致任务重复。
```go
// run创建一个检索流水线，从部分接收部分索引，并通过done通道以相同的顺序返回结果。
// 允许同时运行相同的调度器，以实现检索任务的去重。
func (s *scheduler) run(sections chan uint64, dist chan *request, done chan []byte, quit chan struct{}, wg *sync.WaitGroup) {
    // 创建一个与分发通道大小相同的请求和响应之间的转发通道（因为无论如何，它都会阻塞流水线）。
    pend := make(chan uint64, cap(dist))
    
    // 启动流水线调度器，将用户 -> 分发器 -> 用户之间进行转发。
    wg.Add(2)
    go s.scheduleRequests(sections, dist, pend, quit, wg)
    go s.scheduleDeliveries(pend, done, quit, wg)
}
```

### scheduler的流程图

<img src="../../img/chainindexer_2.png">

矩形代表了channel. 三角形代表外部的方法调用。

1. scheduleRequests goroutine从sections接收到section消息
2. scheduleRequests把接收到的section组装成requtest发送到dist channel，并构建对象response[section]
3. scheduleRequests把上一部的section发送给pend队列。scheduleDelivers接收到pend消息，阻塞在response[section].done上面
4. 外部调用deliver方法，把seciton的request请求结果写入response[section].cached.并关闭response[section].done channel
5. scheduleDelivers接收到response[section].done 信息。 把response[section].cached 发送到done channel

### scheduleRequests
```go
// scheduleRequests从输入通道读取部分检索请求，对流进行去重，
// 并将唯一的检索任务推送到分发通道，以供数据库或网络层处理。
func (s *scheduler) scheduleRequests(reqs chan uint64, dist chan *request, pend chan uint64, quit chan struct{}, wg *sync.WaitGroup) {
	// Clean up the goroutine and pipeline when done
	defer wg.Done()
	defer close(pend)

	// Keep reading and scheduling section requests
	// 持续读取并安排部分请求。
	for {
		select {
		case <-quit:
			return

		case section, ok := <-reqs:
			// New section retrieval requested
			// 收到新的section检索请求。
			if !ok {
				return
			}
			// Deduplicate retrieval requests
			unique := false

			s.lock.Lock()
			if s.responses[section] == nil {
				s.responses[section] = &response{
					done: make(chan struct{}),
				}
				unique = true
			}
			s.lock.Unlock()

			// Schedule the section for retrieval and notify the deliverer to expect this section
			// 安排该部分进行检索，并通知交付员期待该部分的到达。
			if unique {
				select {
				case <-quit:
					return
				case dist <- &request{bit: s.bit, section: section}:
				}
			}
			select {
			case <-quit:
				return
			case pend <- section:
			}
		}
	}
}
```

## generator.go
generator用来产生基于section的布隆过滤器索引数据的对象。 generator内部主要的数据结构是 `bloom[2048][4096]`bit 的数据结构。 输入是4096个header.logBloom数据。 比如第20个header的logBloom存储在 `bloom[0:2048][20]`

数据结构：
```go
const (
	// BloomByteLength表示在头部日志布隆过滤器中使用的字节数。
	BloomByteLength = 256

	// BloomBitLength表示在头部日志布隆过滤器中使用的位数。
	BloomBitLength = 8 * BloomByteLength
)
  
// Generator接收一定数量的布隆过滤器，并生成用于批量过滤的旋转布隆位。
type Generator struct {
	blooms   [types.BloomBitLength][]byte // 旋转布隆用于逐位匹配。
	sections uint                         // 批量处理的部分数量。
	nextSec  uint                         // 添加布隆时设置的下一个部分。
}
```

构造函数：
```go
// NewGenerator创建一个旋转布隆生成器，可以迭代地填充批量布隆过滤器的位。
func NewGenerator(sections uint) (*Generator, error) {
	if sections%8 != 0 {
		return nil, errors.New("section count not multiple of 8")
	}
	b := &Generator{sections: sections}
	for i := 0; i < types.BloomBitLength; i++ {
		b.blooms[i] = make([]byte, sections/8)
	}
	return b, nil
}
```

AddBloom增加一个区块头的logsBloom
```go
// AddBloom接收一个单独的布隆过滤器，并相应地设置内存中的相应位列。
func (b *Generator) AddBloom(index uint, bloom types.Bloom) error {
	// Make sure we're not adding more bloom filters than our capacity
	if b.nextSec >= b.sections {
		return errSectionOutOfBounds
	}
	if b.nextSec != index {
		return errors.New("bloom filter with unexpected index")
	}
	// Rotate the bloom and insert into our collection
    // 将布隆过滤器进行旋转，并插入到我们的集合中。
	byteIndex := b.nextSec / 8
	bitIndex := byte(7 - b.nextSec%8)
	for byt := 0; byt < types.BloomByteLength; byt++ {
		bloomByte := bloom[types.BloomByteLength-1-byt]
		if bloomByte == 0 {
			continue
		}
		base := 8 * byt
		b.blooms[base+7][byteIndex] |= ((bloomByte >> 7) & 1) << bitIndex
		b.blooms[base+6][byteIndex] |= ((bloomByte >> 6) & 1) << bitIndex
		b.blooms[base+5][byteIndex] |= ((bloomByte >> 5) & 1) << bitIndex
		b.blooms[base+4][byteIndex] |= ((bloomByte >> 4) & 1) << bitIndex
		b.blooms[base+3][byteIndex] |= ((bloomByte >> 3) & 1) << bitIndex
		b.blooms[base+2][byteIndex] |= ((bloomByte >> 2) & 1) << bitIndex
		b.blooms[base+1][byteIndex] |= ((bloomByte >> 1) & 1) << bitIndex
		b.blooms[base][byteIndex] |= (bloomByte & 1) << bitIndex
	}
	b.nextSec++
	return nil
}
```

Bitset返回
```go
// Bitset返回在添加了所有布隆过滤器后，属于给定位索引的位向量。
func (b *Generator) Bitset(idx uint) ([]byte, error) {
	if b.nextSec != b.sections {
		return nil, errors.New("bloom not fully generated yet")
	}
	if idx >= types.BloomBitLength {
		return nil, errBloomBitOutOfBounds
	}
	return b.blooms[idx], nil
}
```



