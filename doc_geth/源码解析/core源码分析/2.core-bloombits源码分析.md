## core/bloombits/scheduler.go
scheduler是基于section的布隆过滤器的单个bit值检索的调度。 除了调度检索操作之外，这个结构还可以对请求进行重复数据删除并缓存结果，从而即使在复杂的过滤情况下也可以将网络/数据库开销降至最低。

### 数据结构
request表示一个bloom检索任务，以便优先从本地数据库中或从网络中剪检索。 section 表示区块段号，每段4096个区块， bit代表检索的是布隆过滤器的哪一位(一共有2048位)。这个在之前的(eth-bloombits和filter源码分析.md)中有介绍。
```go
// 请求表示一个布隆过滤器检索任务，可以优先从本地数据库中获取，或者从网络中远程获取。
type request struct {
	section uint64 // 要从中检索位向量的部分索引
	bit     uint   // 要检索向量的位索引在部分内部。
}
```

response当前调度的请求的状态。 没发送一个请求，会生成一个response对象来最终这个请求的状态。 cached用来缓存这个section的结果。
```go
// 响应表示通过调度器请求的位向量的状态。
type response struct {
	cached []byte        // 使用缓存位来去重多个请求
	done   chan struct{} // 使用通道等待完成。
}
```

scheduler
```go
// 调度器负责对属于单个布隆位的整个部分批次进行布隆过滤器检索操作的调度。
// 除了调度检索操作外，该结构体还对请求进行去重，并缓存结果，
// 以在复杂的过滤场景中最小化网络/数据库开销。
type scheduler struct {
	bit       uint                 // 该调度器负责的布隆过滤器中的位的索引
	responses map[uint64]*response // 当前待处理的检索请求或已缓存的响应
	lock      sync.Mutex           // 用于保护响应免受并发访问的锁
}
```

### 构造函数
```go
// newScheduler为特定的位索引创建一个新的布隆过滤器检索调度器。
func newScheduler(idx uint) *scheduler {
	return &scheduler{
		bit:       idx,
		responses: make(map[uint64]*response),
	}
}
```

reset方法
```go
// reset清理之前运行中的任何残留物。在重新启动之前，
// 这是必需的，以确保之前请求但从未交付的状态不会导致死锁。
func (s *scheduler) reset() {
	s.lock.Lock()
	defer s.lock.Unlock()

	for section, res := range s.responses {
		if res.cached == nil {
			delete(s.responses, section)
		}
	}
}
```

### 运行run方法
run方法创建了一个流水线， 从sections channel来接收需要请求的sections，通过done channel来按照请求的顺序返回结果。 并发的运行同样的scheduler是可以的，这样会导致任务重复。
```go
// run创建一个检索流水线，从部分接收部分索引，并通过done通道以相同的顺序返回结果。
// 允许同时运行相同的调度器，以实现检索任务的去重。
func (s *scheduler) run(sections chan uint64, dist chan *request, done chan []byte, quit chan struct{}, wg *sync.WaitGroup) {
    // 创建一个与分发通道大小相同的请求和响应之间的转发通道（因为无论如何，它都会阻塞流水线）。
    pend := make(chan uint64, cap(dist))
    
    // 启动流水线调度器，将用户 -> 分发器 -> 用户之间进行转发。
    wg.Add(2)
    go s.scheduleRequests(sections, dist, pend, quit, wg)
    go s.scheduleDeliveries(pend, done, quit, wg)
}
```

### scheduler的流程图

<img src="../../img/chainindexer_2.png">

矩形代表了channel. 三角形代表外部的方法调用。

1. scheduleRequests goroutine从sections接收到section消息
2. scheduleRequests把接收到的section组装成requtest发送到dist channel，并构建对象response[section]
3. scheduleRequests把上一部的section发送给pend队列。scheduleDelivers接收到pend消息，阻塞在response[section].done上面
4. 外部调用deliver方法，把seciton的request请求结果写入response[section].cached.并关闭response[section].done channel
5. scheduleDelivers接收到response[section].done 信息。 把response[section].cached 发送到done channel

### scheduleRequests
```go
// scheduleRequests从输入通道读取部分检索请求，对流进行去重，
// 并将唯一的检索任务推送到分发通道，以供数据库或网络层处理。
func (s *scheduler) scheduleRequests(reqs chan uint64, dist chan *request, pend chan uint64, quit chan struct{}, wg *sync.WaitGroup) {
	// Clean up the goroutine and pipeline when done
	defer wg.Done()
	defer close(pend)

	// Keep reading and scheduling section requests
	// 持续读取并安排部分请求。
	for {
		select {
		case <-quit:
			return

		case section, ok := <-reqs:
			// New section retrieval requested
			// 收到新的section检索请求。
			if !ok {
				return
			}
			// Deduplicate retrieval requests
			unique := false

			s.lock.Lock()
			if s.responses[section] == nil {
				s.responses[section] = &response{
					done: make(chan struct{}),
				}
				unique = true
			}
			s.lock.Unlock()

			// Schedule the section for retrieval and notify the deliverer to expect this section
			// 安排该部分进行检索，并通知交付员期待该部分的到达。
			if unique {
				select {
				case <-quit:
					return
				case dist <- &request{bit: s.bit, section: section}:
				}
			}
			select {
			case <-quit:
				return
			case pend <- section:
			}
		}
	}
}
```

## generator.go
generator用来产生基于section的布隆过滤器索引数据的对象。 generator内部主要的数据结构是 `bloom[2048][4096]`bit 的数据结构。 输入是4096个header.logBloom数据。 比如第20个header的logBloom存储在 `bloom[0:2048][20]`

数据结构：
```go
const (
	// BloomByteLength表示在头部日志布隆过滤器中使用的字节数。
	BloomByteLength = 256

	// BloomBitLength表示在头部日志布隆过滤器中使用的位数。
	BloomBitLength = 8 * BloomByteLength
)
  
// Generator接收一定数量的布隆过滤器，并生成用于批量过滤的旋转布隆位。
type Generator struct {
	blooms   [types.BloomBitLength][]byte // 旋转布隆用于逐位匹配。
	sections uint                         // 批量处理的部分数量。
	nextSec  uint                         // 添加布隆时设置的下一个部分。
}
```

构造函数：
```go
// NewGenerator创建一个旋转布隆生成器，可以迭代地填充批量布隆过滤器的位。
func NewGenerator(sections uint) (*Generator, error) {
	if sections%8 != 0 {
		return nil, errors.New("section count not multiple of 8")
	}
	b := &Generator{sections: sections}
	for i := 0; i < types.BloomBitLength; i++ {
		b.blooms[i] = make([]byte, sections/8)
	}
	return b, nil
}
```

AddBloom增加一个区块头的logsBloom
```go
// AddBloom接收一个单独的布隆过滤器，并相应地设置内存中的相应位列。
func (b *Generator) AddBloom(index uint, bloom types.Bloom) error {
	// Make sure we're not adding more bloom filters than our capacity
	if b.nextSec >= b.sections {
		return errSectionOutOfBounds
	}
	if b.nextSec != index {
		return errors.New("bloom filter with unexpected index")
	}
	// Rotate the bloom and insert into our collection
    // 将布隆过滤器进行旋转，并插入到我们的集合中。
	byteIndex := b.nextSec / 8
	bitIndex := byte(7 - b.nextSec%8)
	for byt := 0; byt < types.BloomByteLength; byt++ {
		bloomByte := bloom[types.BloomByteLength-1-byt]
		if bloomByte == 0 {
			continue
		}
		base := 8 * byt
		b.blooms[base+7][byteIndex] |= ((bloomByte >> 7) & 1) << bitIndex
		b.blooms[base+6][byteIndex] |= ((bloomByte >> 6) & 1) << bitIndex
		b.blooms[base+5][byteIndex] |= ((bloomByte >> 5) & 1) << bitIndex
		b.blooms[base+4][byteIndex] |= ((bloomByte >> 4) & 1) << bitIndex
		b.blooms[base+3][byteIndex] |= ((bloomByte >> 3) & 1) << bitIndex
		b.blooms[base+2][byteIndex] |= ((bloomByte >> 2) & 1) << bitIndex
		b.blooms[base+1][byteIndex] |= ((bloomByte >> 1) & 1) << bitIndex
		b.blooms[base][byteIndex] |= (bloomByte & 1) << bitIndex
	}
	b.nextSec++
	return nil
}
```

Bitset返回
```go
// Bitset返回在添加了所有布隆过滤器后，属于给定位索引的位向量。
func (b *Generator) Bitset(idx uint) ([]byte, error) {
	if b.nextSec != b.sections {
		return nil, errors.New("bloom not fully generated yet")
	}
	if idx >= types.BloomBitLength {
		return nil, errBloomBitOutOfBounds
	}
	return b.blooms[idx], nil
}
```

## matcher.go
Matcher是一个流水线系统的调度器和逻辑匹配器，它们对比特流执行二进制与/或操作，创建一个潜在块的流来检查数据内容。

数据结构
```go
// partialMatches with a non-nil vector represents a section in which some sub-
// matchers have already found potential matches. Subsequent sub-matchers will
// binary AND their matches with this vector. If vector is nil, it represents a
// section to be processed by the first sub-matcher.
type partialMatches struct {
	section uint64
	bitset  []byte
}

// Retrieval represents a request for retrieval task assignments for a given
// bit with the given number of fetch elements, or a response for such a request.
// It can also have the actual results set to be used as a delivery data struct.
//
// The contest and error fields are used by the light client to terminate matching
// early if an error is encountered on some path of the pipeline.
type Retrieval struct {
    Bit      uint
    Sections []uint64
    Bitsets  [][]byte
    
    Context context.Context
    Error   error
}

// Matcher is a pipelined system of schedulers and logic matchers which perform
// binary AND/OR operations on the bit-streams, creating a stream of potential
// blocks to inspect for data content.
type Matcher struct {
    sectionSize uint64 // Size of the data batches to filter on
    
    filters    [][]bloomIndexes    // Filter the system is matching for
    schedulers map[uint]*scheduler // Retrieval schedulers for loading bloom bits
    
    retrievers chan chan uint       // Retriever processes waiting for bit allocations
    counters   chan chan uint       // Retriever processes waiting for task count reports
    retrievals chan chan *Retrieval // Retriever processes waiting for task allocations
    deliveries chan *Retrieval      // Retriever processes waiting for task response deliveries
    
    running atomic.Bool // Atomic flag whether a session is live or not
}
```

matcher的大体流程图片，途中椭圆代表goroutine. 矩形代表channel。 三角形代表方法调用。

<img src="../../img/matcher_1.png">

1. 首先Matcher根据传入的filter的个数 创建了对应个数的 subMatch 。 每一个subMatch对应了一个filter对象。 每一个subMatch会把自己的查找结果和上一个查找结果按照位与的方式得到新的结果。 如果新的结果所有的bit位都有置位，就会把这个查找结果传递给下一个。 这是实现对所有的filter的结果求与的短路算法。 如果前面的计算已经不能匹配任何东西，那么就不用进行下面的条件的匹配了。
2. Matcher会根据fiters的布隆过滤器的组合下标的个数来启动对应个数的schedule。
3. subMatch会把请求发送给对应的schedule。
4. schedule会把请求调度后通过dist发送给distributor， 在distributor中管理起来。
5. 会启动多个(16)Multiplex线程，从distributor中获取请求，然后把请求发送给bloomRequests队列, startBloomHandlers会访问数据库，拿到数据然后返回给Multiplex。
6. Multiplex通过deliveries通道把回答告诉distributor。
7. distributor调用schedule的deliver方法，把结果发送给schedule
8. schedule把结果返回给subMatch。
9. subMatch把结果进行计算后发送给下一个subMatch进行处理。如果是最后一个subMatch，那么结果会进行处理后发送给results通道。

### 构造函数
需要特别注意的是输入的filters这个参数。 这个参数是一个三维度的数组 `[][]bloomIndexes === [第一维度][第二维度][3]`。
```go
// 这个是filter.go里面的代码，对于理解filters这个参数比较有用。 filter.go是Matcher的调用者。 

// 可以看到无论有多少个addresses，在filters里面也只占一个位置。 filters[0]=addresses
// filters[1] = topics[0] = 多个topic
// filters[2] = topics[1] = 多个topic
// filters[n] = topics[n] = 多个topic

// filter 的参数addresses 和 topics 的过滤算法是， (含有addresses中任意一个address) 并且 (含有topics[0]里面的任意一个topic) 并且 (含有topics[1]里面任意一个topic) 并且 (含有topics[n]里面的任意一个topic)

// 可以看到 对于filter 实行的是  对第一维的数据 执行 与操作， 对于第二维度的数据， 执行或操作。

// 而在NewMatcher方法中，把第三维的具体数据转换成 布隆过滤器的指定三个位置。 所以在filter.go里面的var filters [][][]byte 在Matcher里面的filters变成了 [][][3]

// NewRangeFilter创建一个新的过滤器，它使用布隆过滤器在区块上确定特定区块是否有趣。
func (sys *FilterSystem) NewRangeFilter(begin, end int64, addresses []common.Address, topics [][]common.Hash) *Filter {
    // 将地址和主题过滤条件合并为一个单独的bloombits过滤器系统。
	// 由于bloombits不是位置相关的，允许使用nil主题，并将其合并为一个nil字节切片。
    var filters [][][]byte
    if len(addresses) > 0 {
        filter := make([][]byte, len(addresses))
        for i, address := range addresses {
            filter[i] = address.Bytes()
        }
        filters = append(filters, filter)
    }
    for _, topicList := range topics {
        filter := make([][]byte, len(topicList))
        for i, topic := range topicList {
            filter[i] = topic.Bytes()
        }
        filters = append(filters, filter)
    }
    size, _ := sys.backend.BloomStatus()
    
    // 创建一个通用过滤器，并将其转换为范围过滤器。
    filter := newFilter(sys, addresses, topics)
    
    filter.matcher = bloombits.NewMatcher(size, filters)
    filter.begin = begin
    filter.end = end
    
    return filter
}

// NewMatcher创建一个新的流水线，用于检索布隆位流并对其进行地址和主题过滤。
// 允许将过滤器组件设置为`nil`，并且将导致该过滤器规则被跳过（OR 0x11...1）。
func NewMatcher(sectionSize uint64, filters [][][]byte) *Matcher {
    // Create the matcher instance
    m := &Matcher{
        sectionSize: sectionSize,
        schedulers:  make(map[uint]*scheduler),
        retrievers:  make(chan chan uint),
        counters:    make(chan chan uint),
        retrievals:  make(chan chan *Retrieval),
        deliveries:  make(chan *Retrieval),
    }
    // 计算我们感兴趣的群组的布隆位索引。
    m.filters = nil
    
    for _, filter := range filters {
        // 收集过滤器规则的位索引，特别处理空过滤器的情况。
        if len(filter) == 0 {
            continue
        }
        bloomBits := make([]bloomIndexes, len(filter))
        for i, clause := range filter {
            if clause == nil {
                bloomBits = nil
                break
            }
            bloomBits[i] = calcBloomIndexes(clause)
        }
        // 如果没有空规则，则累积过滤器规则。
        if bloomBits != nil {
            m.filters = append(m.filters, bloomBits)
        }
    }
    // 对于每个位，创建一个调度器来加载/下载位向量。
    for _, bloomIndexLists := range m.filters {
        for _, bloomIndexList := range bloomIndexLists {
            for _, bloomIndex := range bloomIndexList {
                m.addScheduler(bloomIndex)
            }
        }
    }
    return m
}
```

### Start 启动
```go
// Start函数开始匹配过程，并返回在给定区块范围内的布隆过滤器匹配结果的流。
// 如果在该范围内没有更多的匹配结果，结果通道将被关闭。
func (m *Matcher) Start(ctx context.Context, begin, end uint64, results chan uint64) (*MatcherSession, error) {
	// Make sure we're not creating concurrent sessions
	if m.running.Swap(true) {
		return nil, errors.New("matcher already running")
	}
	defer m.running.Store(false)

	// Initiate a new matching round
	// 启动了一个session，作为返回值，管理查找的生命周期。
	session := &MatcherSession{
		matcher: m,
		quit:    make(chan struct{}),
		ctx:     ctx,
	}
	for _, scheduler := range m.schedulers {
		scheduler.reset()
	}
	// 这个运行会建立起流程，返回了一个partialMatches类型的管道表示查询的部分结果。
	sink := m.run(begin, end, cap(results), session)

	// Read the output from the result sink and deliver to the user
	session.pend.Add(1)
	go func() {
		defer session.pend.Done()
		defer close(results)

		for {
			select {
			case <-session.quit:
				return

			case res, ok := <-sink:
				// New match result found
                // 找到返回结果 因为返回值是 section和 section中哪些区块可能有值的bitmap
				// 所以需要遍历这个bitmap，找到那些被置位的区块，把区块号返回回去。
				if !ok {
					return
				}
				// Calculate the first and last blocks of the section
				sectionStart := res.section * m.sectionSize

				first := sectionStart
				if begin > first {
					first = begin
				}
				last := sectionStart + m.sectionSize - 1
				if end < last {
					last = end
				}
				// Iterate over all the blocks in the section and return the matching ones
				for i := first; i <= last; i++ {
					// Skip the entire byte if no matches are found inside (and we're processing an entire byte!)
					next := res.bitset[(i-sectionStart)/8]
					if next == 0 {
						if i%8 == 0 {
							i += 7
						}
						continue
					}
					// Some bit it set, do the actual submatching
					if bit := 7 - i%8; next&(1<<bit) != 0 {
						select {
						case <-session.quit:
							return
						case results <- i:
						}
					}
				}
			}
		}
	}()
	return session, nil
}
```

### run方法
```go
// run creates a daisy-chain of sub-matchers, one for the address set and one
// for each topic set, each sub-matcher receiving a section only if the previous
// ones have all found a potential match in one of the blocks of the section,
// then binary AND-ing its own matches and forwarding the result to the next one.
//
// The method starts feeding the section indexes into the first sub-matcher on a
// new goroutine and returns a sink channel receiving the results.
// 
// 创建一个子匹配器的流水线，一个用于地址集，一个用于每个主题集，
// 每个子匹配器只有在先前的所有子块都在该部分的一个块中找到可能的匹配时才接收一个部分，
// 然后把接收到的和自己的匹配，并将结果转交给下一个。
// 
// 运行函数创建了一个子匹配器的daisy-chain，一个用于地址集，每个主题集一个，
// 每个子匹配器只有在前面的子匹配器在某个区块中找到潜在匹配时才会接收到一个区块，
// 然后将自己的匹配结果与前一个匹配器的结果进行二进制AND运算，并将结果转发给下一个匹配器。
// 该方法将区块索引输入到第一个子匹配器的新goroutine中，并返回一个接收结果的sink通道。
func (m *Matcher) run(begin, end uint64, buffer int, session *MatcherSession) chan *partialMatches {
	// Create the source channel and feed section indexes into
	source := make(chan *partialMatches, buffer)

	session.pend.Add(1)
	go func() {
		defer session.pend.Done()
		defer close(source)

		for i := begin / m.sectionSize; i <= end/m.sectionSize; i++ {
			// 这个for循环 构造了subMatch的第一个输入源，剩下的subMatch把上一个的结果作为自己的源
			// 这个源的bitset字段都是0xff，代表完全的匹配，它将和我们这一步的匹配进行与操作，得到这一步匹配的结果。
			select {
			case <-session.quit:
				return
			case source <- &partialMatches{i, bytes.Repeat([]byte{0xff}, int(m.sectionSize/8))}:
			}
		}
	}()
	// Assemble the daisy-chained filtering pipeline
	next := source
	dist := make(chan *request, buffer)

	// 构建流水线， 前一个的输出作为下一个subMatch的输入。
	for _, bloom := range m.filters {
		next = m.subMatch(next, dist, bloom, session)
	}
	// Start the request distribution
	session.pend.Add(1)
	go m.distributor(dist, session)

	return next
}
```

### subMatch函数
subMatch是最重要的一个函数， 把`filters[][][3]`的 第一维度的与，第二维度的或， 第三维度的与操作 结合在一起。
```go
// subMatch creates a sub-matcher that filters for a set of addresses or topics, binary OR-s those matches, then
// binary AND-s the result to the daisy-chain input (source) and forwards it to the daisy-chain output.
// The matches of each address/topic are calculated by fetching the given sections of the three bloom bit indexes belonging to
// that address/topic, and binary AND-ing those vectors together.
// 
// subMatch创建一个子匹配器，用于过滤一组地址或主题，对这些主题进行bit位或操作，
// 然后将上一个结果与当前过滤结果进行位与操作，如果结果不全位空，就把结果传递给下一个子匹配器。
// 每个地址/topic的匹配是通过获取属于该地址/topic的三个布隆过滤器位索引的给定部分以及
// 将这些向量二进制AND并在一起来计算的。
//
// 传入的bloom []bloomIndexes参数是filters的第二,第三维度  [][3]  
func (m *Matcher) subMatch(source chan *partialMatches, dist chan *request, bloom []bloomIndexes, session *MatcherSession) chan *partialMatches {
	// Start the concurrent schedulers for each bit required by the bloom filter
    // 为布隆过滤器所需的每个位启动并发调度器。
	sectionSources := make([][3]chan uint64, len(bloom))
	sectionSinks := make([][3]chan []byte, len(bloom))
    for i, bits := range bloom { // i代表了第二维度的数量
        for j, bit := range bits {  //j 代表了布隆过滤器的下标 肯定只有三个 取值(0-2048)
            sectionSources[i][j] = make(chan uint64, cap(source)) // 创建scheduler的输入channel
            sectionSinks[i][j] = make(chan []byte, cap(source)) // 创建 scheduler的输出channel
            // 对这个bit发起调度请求， 通过sectionSources[i][j]传递需要查询的section
            // 通过sectionSinks[i][j]来接收结果
            // dist 是scheduler传递请求的通道。 这个在scheduler的介绍里面有。
            m.schedulers[bit].run(sectionSources[i][j], dist, sectionSinks[i][j], session.quit, &session.pend)
        }
    }

	process := make(chan *partialMatches, cap(source)) // 在发起抓取后，来自源的条目被转发到这里。
	results := make(chan *partialMatches, cap(source))

	session.pend.Add(2)
	go func() {
		// 关闭goroutine并终止所有源通道。
		defer session.pend.Done()
		defer close(process)

		defer func() {
			for _, bloomSources := range sectionSources {
				for _, bitSource := range bloomSources {
					close(bitSource)
				}
			}
		}()
		// 从源通道读取区块，并将其多路复用到所有位调度器中。
		for {
			select {
			case <-session.quit:
				return

			case subres, ok := <-source:
				// New subresult from previous link
				if !ok {
					return
				}
				// Multiplex the section index to all bit-schedulers
				for _, bloomSources := range sectionSources {
					for _, bitSource := range bloomSources {
						// 传递给上面的所有的scheduler的输入通道。 申请对这些
						// section 的指定bit进行查找。 结果会发送给sectionSinks[i][j]
						select {
						case <-session.quit:
							return
						case bitSource <- subres.section:
						}
					}
				}
				// 通知处理器该区块将可用。
				select {
				case <-session.quit:
					return
				case process <- subres:
				}
			}
		}
	}()

	go func() {
		// 关闭goroutine并终止最终的sink通道。
		defer session.pend.Done()
		defer close(results)

		// 读取源通知并收集传递的结果。
		for {
			select {
			case <-session.quit:
				return

			case subres, ok := <-process:
				// 这里有个问题。 有没有可能乱序。 因为通道都是有缓存的。 可能查询得快慢导致
                // 查看了scheduler的实现， scheduler是保证顺序的。怎么进来，就会怎么出去。
				//  Notified of a section being retrieved
				// 收到一个区块被检索的通知。
				if !ok {
					return
				}
				// 收集所有子结果并将它们合并在一起。
				var orVector []byte
				for _, bloomSinks := range sectionSinks {
					var andVector []byte
					for _, bitSink := range bloomSinks { // 这里可以接收到三个值 每个代表了对应下标的 布隆过滤器的值,对这三个值进行与操作，就可以得到那些区块可能存在对应的值。
						var data []byte
						select {
						case <-session.quit:
							return
						case data = <-bitSink:
						}
						if andVector == nil {
							andVector = make([]byte, int(m.sectionSize/8))
							copy(andVector, data)
						} else {
							bitutil.ANDBytes(andVector, andVector, data)
						}
					}
					if orVector == nil {
						orVector = andVector
					} else {
						bitutil.ORBytes(orVector, orVector, andVector)
					}
				}

				if orVector == nil { // 可能通道被关闭了。 没有查询到任何值
					orVector = make([]byte, int(m.sectionSize/8))
				}
				if subres.bitset != nil {
					// 和输入的上一次的结果进行与操作。 记得最开始这个值被初始化为全1
					bitutil.ANDBytes(orVector, orVector, subres.bitset)
				}
				if bitutil.TestBytes(orVector) { // 如果不全为0 那么添加到结果。可能会给下一个匹配。或者是返回。
					select {
					case <-session.quit:
						return
					case results <- &partialMatches{subres.section, orVector}:
					}
				}
			}
		}
	}()
	return results
}
```


















